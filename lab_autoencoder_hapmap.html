<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Marcin Kierczak | NBIS | 08-Dec-2020" />


<title>Autoencoder Lab in R</title>

<script src="lab_autoencoder_hapmap_files/header-attrs-2.5/header-attrs.js"></script>
<script src="lab_autoencoder_hapmap_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="lab_autoencoder_hapmap_files/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="lab_autoencoder_hapmap_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="lab_autoencoder_hapmap_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="lab_autoencoder_hapmap_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="lab_autoencoder_hapmap_files/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="lab_autoencoder_hapmap_files/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="lab_autoencoder_hapmap_files/tocify-1.9.1/jquery.tocify.js"></script>
<script src="lab_autoencoder_hapmap_files/navigation-1.1/tabsets.js"></script>
<link href="lab_autoencoder_hapmap_files/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="lab_autoencoder_hapmap_files/pagedtable-1.1/js/pagedtable.js"></script>
<link href="lab_autoencoder_hapmap_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="lab_autoencoder_hapmap_files/anchor-sections-1.0/anchor-sections.js"></script>
<link href="lab_autoencoder_hapmap_files/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="lab_autoencoder_hapmap_files/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link id="font-awesome-1-attachment" rel="attachment" href="lab_autoencoder_hapmap_files/font-awesome-5.1.0/fonts/fontawesome-webfont.ttf"/>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="assets/lab.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Autoencoder Lab in R</h1>
<h3 class="subtitle">visualizing HapMap phase 3 populations</h3>
<h4 class="author">Marcin Kierczak | <b>NBIS</b> | 08-Dec-2020</h4>

</div>


<!-- rmd lab header -->
<!-- custom fonts -->
<p><link href="https://fonts.googleapis.com/css?family=Roboto|Source+Sans+Pro:300,400,600|Ubuntu+Mono&amp;subset=latin-ext" rel="stylesheet"></p>
<p><img src="assets/logo.svg" alt="logo" class="trlogo"></p>
<p><br>
<!-- ------------ Only edit title, subtitle & author above this ------------ --></p>
<div id="synopsis" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Synopsis</h1>
<p>In this lab, we will use chip genotyping data from Hap Map phase 3 project. These data come from a number of humans belonging to different ethnic groups/populations. The groups are genetically distinct but, in some cases, closely related and thus somewhat difficult to distinguish. We will first try to visualize population structure using classical dimensionality reduction techniques like PCA and MDS and next, we will build autoencoder and see if it does any better in separating different populations. We will work in R and use <code>keras</code> interface to <code>TensorFlow</code>.</p>
</div>
<div id="working-environment" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Working environment</h1>
<p>Before we begin, we have to set up a proper working 🏭 environment. Follow the points below on your way to success. 😄</p>
<ul>
<li>Install R package <code>renv</code> that will manage your working environment in a way similar to <code>Conda</code> 🐍. It is a bit smarter than <code>Conda</code>, since libraries can be shared between projects, so using it across your projects will (hopefully) not result in disk space shortage 😕.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;renv&#39;</span>)</span></code></pre></div>
<ul>
<li><p><a href="assets/renv.lock">Download my <code>renv.lock</code></a> file. It is a text file that tells the <code>renv</code> package how to re-create the environment. Place the file in your working 📁.</p></li>
<li><p>Re-create the environment from the <code>renv.lock</code> snapshot.</p></li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>renv<span class="sc">::</span><span class="fu">restore</span>(<span class="at">lockfile =</span> <span class="st">&#39;renv.lock&#39;</span>)</span></code></pre></div>
<ul>
<li>Install <code>keras</code>. Keras will be installed by the R <code>keras</code> package that will, in turn, use either <code>conda</code> or <code>virtualenv</code>. It will also install TensorFlow for you.</li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">install_keras</span>()</span></code></pre></div>
<ul>
<li>Congratulate yourself! 💪</li>
</ul>
</div>
<div id="background" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Background</h1>
<p>The purpose of this lab is to evaluate the possibility of using autoencoder as a replacement/complement to more “classical” linear dimensionality reduction methods such as PCA or MDS. These are commonly used for, e.g. visualizing population structure in genetics. One of the main motivations is that when inferring genomic kinship from a large number of markers <code>M</code> (large enough to capture population structure at fine level), one necessarily introduces correlations between variables, here, genetic markers. This is predominantly due to the linkage disequilibrium, but also due to the large <code>M</code> that, even by pure chance, introduces correlated variables to the data. This correlation structure introduces non-linearity that, in turn, makes the data not very well suitable for PCA/MDS since both approaches rely on computing kinship matrix determinants that, for a lot of highly correlated variables, become 0 and prevent us from computing exact solutions (division by zero is undefined).</p>
<p>Here, the working hypotheses is that by choosing non-linear activation functions, e.g. ReLU, one can circumvent this problem and use autoencoder approach to reduce the dimensionality by embedding kinship data in a low dimensional latent representation space that, in turn, can easily be visualized. The idea emerged during the EMBL conference <em>Reconstructing the Human Past</em>, Heidelberg 🍺, April 2019, in a number of discussions with Nikolay Oskolkov 👨‍🔬 and other conference participants: 🐿, 🦓 and 🐉.</p>
<div id="data" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Data</h2>
<p>Data comes from the HapMap phase 3 project. Here, for computational feasibility, we will be using smaller dataset. I have pre-selected 5,000 autosomal markers with call rate of 100%. We will not be dealing with missing data here although autoencoders, in contrast to PCA and MDS, can.</p>
<p>HapMap 3 populations:</p>
<ul>
<li>ASW – African 🌍 ancestry in Southwest USA 🇺🇸</li>
<li>CEU – Utah residents with Northern and Western European 🌍 ancestry from the CEPH collection</li>
<li>CHB – Han Chinese in Beijing, China 🇨🇳</li>
<li>CHD – Chinese 🇨🇳 in Metropolitan Denver, Colorado ⛰</li>
<li>GIH – Gujarati Indians 🇮🇳 in Houston, Texas</li>
<li>JPT – Japanese in Tokyo, Japan 🇯🇵</li>
<li>LWK – Luhya in Webuye, Kenya 🇰🇪</li>
<li>MEX – Mexican 🇲🇽 ancestry in Los Angeles, California 🐻</li>
<li>MKK – Maasai in Kinyawa, Kenya 🇰🇪</li>
<li>TSI – Toscans 🛵 in Italy 🇮🇹</li>
<li>YRI – Yoruba in Ibadan, Nigeria 🇳🇬</li>
</ul>
</div>
</div>
<div id="preparations" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Preparations</h1>
<p>First, we need to <a href="assets/autosomal_5k.rdat">download the <code>autosomal_5k.rdat</code> dataset</a>. Data are stored as an R data object, more specifically, a <code>GenABEL::gwaa-data</code> class object consisting of 1184 individuals, each genotyped at 5000 loci. The loci are randomly spread across autosomes. If anyone is curious, the code below was used to generate this subset of the original dataset.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">load.gwaa.data</span>(<span class="st">&quot;hapmap3_r2_b36_fwd.consensus.qc.poly.csv&quot;</span>, <span class="st">&quot;hapmap3_r2_b36_fwd.consensus.qc.poly.out&quot;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data_auto <span class="ot">&lt;-</span> data[, <span class="fu">autosomal</span>(data)]</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rm</span>(data)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>snp_subset <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nsnps</span>(data_auto), <span class="at">size =</span> <span class="dv">50000</span>, <span class="at">replace =</span> F)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>data_auto <span class="ot">&lt;-</span> data_auto[,snp_subset]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>qc1 <span class="ot">&lt;-</span> <span class="fu">check.marker</span>(data_auto, <span class="at">callrate =</span> <span class="fl">1.0</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>data_autosomal <span class="ot">&lt;-</span> data_auto[qc1<span class="sc">$</span>idok, qc1<span class="sc">$</span>snpok]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>snp_subset <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nsnps</span>(data_autosomal), <span class="at">size =</span> <span class="dv">5000</span>, <span class="at">replace =</span> F)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>data_autosomal <span class="ot">&lt;-</span> data_autosomal[,snp_subset]</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">save</span>(data_autosomal, <span class="at">file =</span> <span class="st">&quot;./autosomal_5k.rdat&quot;</span>)</span></code></pre></div>
<p>We will begin by setting your working directory and loading necessary packages (they should be automatically installed when you restored my environment using <code>renv::restore()</code>).</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(renv)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(here)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(GenABEL)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kerasR)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggbiplot)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>here<span class="sc">::</span><span class="fu">here</span>() <span class="co"># check what is our current working directory</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>base<span class="sc">::</span><span class="fu">load</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">&#39;assets/autosomal_5k.rdat&#39;</span>))</span></code></pre></div>
<pre><code>## [1] &quot;/Users/kiero/Dropbox/WABI/Teaching/autoencoders_workshop&quot;</code></pre>
</div>
<div id="benchmark" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Benchmark</h1>
<p>First, to have some sort of a benchmark 📏, we will do PCA and MDS (which should be more or less equivalent) on the genomic kinship matrix to visualize patterns present in the data.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute genomic kinship-based distance</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>gkin <span class="ot">&lt;-</span> <span class="fu">ibs</span>(data_autosomal, <span class="at">weight =</span> <span class="st">&#39;freq&#39;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>dm <span class="ot">&lt;-</span> <span class="fu">as.dist</span>(.<span class="dv">5</span> <span class="sc">-</span> gkin) <span class="co"># Normalize it</span></span></code></pre></div>
<div id="pca" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> PCA</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>pca <span class="ot">&lt;-</span> stats<span class="sc">::</span><span class="fu">prcomp</span>(dm)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>g <span class="ot">&lt;-</span> <span class="fu">ggbiplot</span>(pca, <span class="at">obs.scale =</span> <span class="dv">1</span>, <span class="at">var.scale =</span> <span class="dv">1</span>, </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">groups =</span> data_autosomal<span class="sc">@</span>phdata<span class="sc">$</span>population, <span class="at">ellipse =</span> F, </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">circle =</span> <span class="cn">TRUE</span>, <span class="at">var.axes =</span> F) <span class="sc">+</span> </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">&#39;&#39;</span>) <span class="sc">+</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.direction =</span> <span class="st">&#39;horizontal&#39;</span>, </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">legend.position =</span> <span class="st">&#39;top&#39;</span>) <span class="sc">+</span> </span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(g)</span></code></pre></div>
<p><img src="lab_autoencoder_hapmap_files/figure-html/perform_pca-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
</div>
<div id="mds" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> MDS</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>ibs <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(<span class="fu">cmdscale</span>(dm))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>ibs <span class="ot">&lt;-</span> <span class="fu">cbind</span>(ibs, <span class="at">pop =</span> data_autosomal<span class="sc">@</span>phdata<span class="sc">$</span>population)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ibs, <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x=</span>V1, <span class="at">y=</span>V2, <span class="at">col=</span>pop)) <span class="sc">+</span> </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span> </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="lab_autoencoder_hapmap_files/figure-html/perform_mds-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
</div>
</div>
<div id="autoencoder" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Autoencoder</h1>
<div id="model-parameters" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Model parameters</h2>
<p>Below, we define model parameters: loss function 📈 set to the mean squared error and activation layer set to ReLU. One can refer to <a href="https://keras.io/api/metrics/">Keras docs</a> for more insights.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="ot">&lt;-</span> <span class="st">&#39;mean_squared_error&#39;</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>act <span class="ot">&lt;-</span> <span class="st">&#39;relu&#39;</span></span></code></pre></div>
</div>
<div id="prepare-input" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Prepare input</h2>
<p>Input data is first normalized so that:</p>
<ul>
<li>homozygotes <code>AA</code> are set to 1</li>
<li>heterozygotes <code>aA</code> and <code>Aa</code> to 0.5 and</li>
<li>homozygotes <code>aa</code> to 0.</li>
</ul>
<p>Next, the data are randomly 🎲 split into the validation (20%) and the training (80%) set.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Encode genotypes </span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>geno_matrix <span class="ot">&lt;-</span> <span class="fu">as.double</span>(data_autosomal)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>geno_tensor <span class="ot">&lt;-</span> geno_matrix<span class="sc">/</span><span class="dv">2</span> <span class="co"># alternative approach: keras::to_categorical(geno_matrix)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly split into the training and the validation set</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>n_rows <span class="ot">&lt;-</span> <span class="fu">dim</span>(geno_tensor)[<span class="dv">1</span>]</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>n_rows, <span class="at">size =</span> <span class="fl">0.8</span> <span class="sc">*</span> n_rows, <span class="at">replace =</span> F) </span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> geno_tensor[train_idx, ]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>valid_data <span class="ot">&lt;-</span> geno_tensor[<span class="sc">-</span>train_idx, ]</span></code></pre></div>
</div>
<div id="define-the-architecture" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Define the architecture</h2>
<p>Here, we define the architecture 🏙 of our autoencoder. Autoencoders are symmetrical creatures, like 🦋. It implies that the <em>decoder</em> is the reversal of the <em>encoder</em>, symmetrical about the low-D latent representation layer (a.k.a bottleneck 🍾, in our case 2D). Some dropout layers were added for regularization, i.e. to prevent overfitting.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>input_layer <span class="ot">&lt;-</span> <span class="fu">layer_input</span>(<span class="at">shape =</span> <span class="fu">dim</span>(train_data)[<span class="dv">2</span>])</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>encoder <span class="ot">&lt;-</span> </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  input_layer <span class="sc">%&gt;%</span> </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1500</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span> </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_batch_normalization</span>() <span class="sc">%&gt;%</span> <span class="co"># accelerate the training and make it more stable (a trick of the trade:-)</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.2</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">500</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">25</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">2</span>) <span class="co"># bottleneck</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>decoder <span class="ot">&lt;-</span> </span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>  encoder <span class="sc">%&gt;%</span> </span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">25</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span> </span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.2</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">500</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dropout</span>(<span class="at">rate =</span> <span class="fl">0.1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1500</span>, <span class="at">activation =</span> act) <span class="sc">%&gt;%</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="fu">dim</span>(train_data)[<span class="dv">2</span>], <span class="at">activation =</span> <span class="st">&quot;sigmoid&quot;</span>)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>autoencoder_model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> input_layer, <span class="at">outputs =</span> decoder)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>autoencoder_model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> loss_fn,</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">&#39;adam&#39;</span>,</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>() <span class="co"># here you specify a list of metrics, like accuracy or AUC when applicable</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Now, we can 👀 how our compiled model looks like:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(autoencoder_model)</span></code></pre></div>
<pre class="smallest"><code>## Model: &quot;model&quot;
## ________________________________________________________________________________
## Layer (type)                        Output Shape                    Param #     
## ================================================================================
## input_1 (InputLayer)                [(None, 5000)]                  0           
## ________________________________________________________________________________
## dense_3 (Dense)                     (None, 1500)                    7501500     
## ________________________________________________________________________________
## batch_normalization (BatchNormaliza (None, 1500)                    6000        
## ________________________________________________________________________________
## dropout_1 (Dropout)                 (None, 1500)                    0           
## ________________________________________________________________________________
## dense_2 (Dense)                     (None, 500)                     750500      
## ________________________________________________________________________________
## dropout (Dropout)                   (None, 500)                     0           
## ________________________________________________________________________________
## dense_1 (Dense)                     (None, 25)                      12525       
## ________________________________________________________________________________
## dense (Dense)                       (None, 2)                       52          
## ________________________________________________________________________________
## dense_7 (Dense)                     (None, 25)                      75          
## ________________________________________________________________________________
## dropout_3 (Dropout)                 (None, 25)                      0           
## ________________________________________________________________________________
## dense_6 (Dense)                     (None, 500)                     13000       
## ________________________________________________________________________________
## dropout_2 (Dropout)                 (None, 500)                     0           
## ________________________________________________________________________________
## dense_5 (Dense)                     (None, 1500)                    751500      
## ________________________________________________________________________________
## dense_4 (Dense)                     (None, 5000)                    7505000     
## ================================================================================
## Total params: 16,540,152
## Trainable params: 16,537,152
## Non-trainable params: 3,000
## ________________________________________________________________________________</code></pre>
</div>
<div id="the-training-phase" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> The training 🏃 phase</h2>
<p>We are ready to train our model now. By setting <code>shuffle = T</code>, we make sure the training data will be 🎲 re-shuffled 🎲 in each epoch and <code>batch_size = 256</code> tells <code>keras</code> to use 256 samples per gradient update (improves efficiency). We want 20% of the training data to be used for validation at each epoch <code>validation_split = .2</code> and we can also specify some custom callback functions to, e.g. introduce custom early stopping 🛑 criteria.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>history <span class="ot">&lt;-</span> autoencoder_model <span class="sc">%&gt;%</span> <span class="fu">fit</span>(</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> train_data, </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> train_data, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">epochs =</span> <span class="dv">60</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shuffle =</span> T, </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">batch_size =</span> <span class="dv">256</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">validation_split =</span> .<span class="dv">2</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">#callbacks = list(checkpoint, early_stopping)</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(history) <span class="sc">+</span> <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="lab_autoencoder_hapmap_files/figure-html/autoencoder_train-1.svg" width="672" style="display: block; margin: auto auto auto 0;" /></p>
<p>Now the model has been trained, loss and accuracy are evaluated on both the initial training data at each epoch 🎲 split into the new training (80%) and the new test (20%) set.</p>
<div id="encoder" class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Encoder</h3>
<p>Following the training phase, we will build 🏗 the encoder.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>autoencoder_weights <span class="ot">&lt;-</span> autoencoder_model <span class="sc">%&gt;%</span> keras<span class="sc">::</span><span class="fu">get_weights</span>()</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>keras<span class="sc">::</span><span class="fu">save_model_weights_hdf5</span>(<span class="at">object =</span> autoencoder_model, </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                               <span class="at">filepath =</span> <span class="st">&#39;./autoencoder_weights.hdf5&#39;</span>, </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>                               <span class="at">overwrite =</span> <span class="cn">TRUE</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="ot">&lt;-</span> <span class="fu">keras_model</span>(<span class="at">inputs =</span> input_layer, <span class="at">outputs =</span> encoder)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="sc">%&gt;%</span> keras<span class="sc">::</span><span class="fu">load_model_weights_hdf5</span>(<span class="at">filepath =</span> <span class="st">&quot;./autoencoder_weights.hdf5&quot;</span>, </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>                                                 <span class="at">skip_mismatch =</span> <span class="cn">TRUE</span>,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>                                                 <span class="at">by_name =</span> T)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>encoder_model <span class="sc">%&gt;%</span> <span class="fu">compile</span>(</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">loss =</span> loss_fn,</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">optimizer =</span> <span class="st">&#39;adam&#39;</span>,</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">metrics =</span> <span class="fu">c</span>(<span class="st">&#39;MeanSquaredError&#39;</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</div>
<div id="embedding-original-data" class="section level3" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Embedding original data</h3>
<p>Now, original data can be embedded in the low-dimensional space using the encoder.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>embeded_points <span class="ot">&lt;-</span> </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>  encoder_model <span class="sc">%&gt;%</span> </span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  keras<span class="sc">::</span><span class="fu">predict_on_batch</span>(<span class="at">x =</span> geno_tensor)</span></code></pre></div>
</div>
</div>
<div id="final-results" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Final results</h2>
<p>Now, we can see how the embeddings compare with the MDS approach.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>embedded <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(embeded_points[,<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>], </span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">pop =</span> data_autosomal<span class="sc">@</span>phdata<span class="sc">$</span>population, </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>                       <span class="at">type=</span><span class="st">&#39;emb&#39;</span>)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>mds <span class="ot">&lt;-</span> <span class="fu">cbind</span>(ibs, <span class="at">type=</span><span class="st">&#39;mds&#39;</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(mds) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;x&#39;</span>, <span class="st">&#39;y&#39;</span>, <span class="st">&#39;pop&#39;</span>, <span class="st">&#39;type&#39;</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(embedded) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;x&#39;</span>, <span class="st">&#39;y&#39;</span>, <span class="st">&#39;pop&#39;</span>, <span class="st">&#39;type&#39;</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">rbind</span>(embedded, mds)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>dat <span class="sc">%&gt;%</span> <span class="fu">ggplot</span>(<span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y, <span class="at">col=</span>pop)) <span class="sc">+</span> </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>type, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="lab_autoencoder_hapmap_files/figure-html/unnamed-chunk-10-1.svg" width="672" style="display: block; margin: auto auto auto 0;" />
Are the results produced by autoencoder better? I think it still has problems separating two non-homogenous clusters but it seems that the resolution achieved on the big clumps is better. Probably we should measure this in a more objective way, but since you know how to make autoencoders in R, you can do all sorts of experiments 🔎 now! Good luck with your future endavours.</p>
</div>
</div>
<div id="tasks-and-questions" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Tasks and questions</h1>
<div id="training-phase" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Training phase</h2>
<ul>
<li>Why both <code>x</code> and <code>y</code> have the same value?</li>
<li>Try using external validation data instead. Set <code>validation_data = list(valid_data, valid_data)</code> that will override the <code>validation_split</code> argument. What happens? Remember that, with every epoch, there may occur some 💧leakage💧 of the data from the validation set to the training set via network weights…</li>
<li>What happens if we do not shuffle?</li>
<li>How does increasing the number of epochs affect model’s performance? Try, e.g. 120 epochs.</li>
<li>Introduce an early stopping criterion using callback function.
A custom callback function may look like:</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># checkpoint &lt;- callback_model_checkpoint(</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#   filepath = &quot;model.hdf5&quot;, </span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   save_best_only = TRUE, </span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   period = 1,</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   verbose = 1</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># early_stopping &lt;- callback_early_stopping(patience = 5)</span></span></code></pre></div>
</div>
<div id="more-experiments" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> More experiments</h2>
<ul>
<li><p>Try using autoencoder to reduce dimensionality to more dimensions than 2, say 20 and apply PCA on this latent space to visualize it in 2D. Did you get better resolution? (non-linear -&gt; linear reduction)</p></li>
<li><p>Can you think of using autoencoder on a latent space obtained with MDS or PCA (linear -&gt; non_linear reduction).</p></li>
<li><p>What about chaining two non-linear methods, e.g. <a href="https://cran.r-project.org/web/packages/umap/vignettes/umap.html">UMAP</a> on top of autoencoder?</p></li>
</ul>
</div>
</div>
<div id="reproducibility-note" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Reproducibility note</h1>
<p>Experimental conditions:</p>
<ul>
<li>Moon phase: 🌗.</li>
<li>Sun in the Zodiac sign of: 🏹.</li>
<li>Chinese year of: 🐀.</li>
<li>Recorded average strength of electromagic field: <span class="math inline">\(0.74\mu M\)</span> 🧙.</li>
<li>Witcher 🐺 on duty: Geralt of Rivia.</li>
</ul>
<!-- --------------------- Do not edit this and below ---------------------- -->
</div>
<div id="session-info" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Session info</h1>
<pre><code>## R version 4.0.3 (2020-10-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Big Sur 10.16
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices datasets  utils     methods  
## [8] base     
## 
## other attached packages:
##  [1] ggbiplot_0.55      scales_1.1.1       plyr_1.8.6         ggplot2_3.3.2     
##  [5] kerasR_0.6.1       keras_2.3.0.0      GenABEL_1.8-0      GenABEL.data_1.0.0
##  [9] MASS_7.3-53        here_1.0.0         renv_0.12.3        captioner_2.2.3   
## [13] bookdown_0.21      knitr_1.30        
## 
## loaded via a namespace (and not attached):
##  [1] reticulate_1.18   xfun_0.19         purrr_0.3.4       splines_4.0.3    
##  [5] lattice_0.20-41   colorspace_2.0-0  generics_0.1.0    vctrs_0.3.5      
##  [9] htmltools_0.5.0   mgcv_1.8-33       emo_0.0.0.9000    yaml_2.2.1       
## [13] base64enc_0.1-3   rlang_0.4.9       pillar_1.4.7      glue_1.4.2       
## [17] withr_2.3.0       lifecycle_0.2.0   tensorflow_2.2.0  stringr_1.4.0    
## [21] munsell_0.5.0     gtable_0.3.0      evaluate_0.14     labeling_0.4.2   
## [25] tfruns_1.4        Rcpp_1.0.5        jsonlite_1.7.1    farver_2.0.3     
## [29] digest_0.6.27     stringi_1.5.3     rprojroot_2.0.2   tools_4.0.3      
## [33] magrittr_2.0.1    tibble_3.0.4      crayon_1.3.4      whisker_0.4      
## [37] pkgconfig_2.0.3   zeallot_0.1.0     ellipsis_0.3.1    Matrix_1.2-18    
## [41] lubridate_1.7.9.2 assertthat_0.2.1  rmarkdown_2.5     rstudioapi_0.13  
## [45] R6_2.5.0          nlme_3.1-149      compiler_4.0.3</code></pre>
<p style="text-align: left; font-size: small;">
Built on: <i class="fa fa-calendar" aria-hidden="true"></i> 08-Dec-2020 at <i class="fa fa-clock-o" aria-hidden="true"></i> 09:28:38.
</p>
<hr/>
<div>
<p><span style="float:left; vertical-align:middle">
<b>2020</b> <a href="https://nbis.se/">NBIS</a> | <a href="https://www.scilifelab.se/">SciLifeLab</a>
</span>
<span style="float:right; vertical-align:middle">
<span class="footericon" style="padding-right:4px; padding-left:4px">
<a href="https://nbis.se/"><i class="fas fa-globe-americas"></i></a>
</span>
<span class="footericon" style="padding-right:4px; padding-left:4px">
<a href="https://twitter.com/NBISwe"><i class="fab fa-twitter"></i></a>
</span>
<span class="footericon" style="padding-left:4px">
<a href="https://www.linkedin.com/company/nbisweden/"><i class="fab fa-linkedin"></i></a>
</span>
</span></p>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
